{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Templates (first 5 rows):\n",
      "  hierarchy_level                                         user_query  \\\n",
      "0          Level1  For the plan '{Plan Name}' and explain its pre...   \n",
      "1          Level1  For the plan '{Plan Name}' and what premium op...   \n",
      "2          Level1  For the plan '{Plan Name}' and what is its pre...   \n",
      "3          Level1  Regarding plan '{Plan Name}' and what premium ...   \n",
      "4          Level1  I need details for plan '{Plan Name}' and what...   \n",
      "\n",
      "  target_columns                               output_template  \n",
      "0   Premium Type  It is offered in the {Premium Type} category  \n",
      "1   Premium Type  The available premium type is {Premium Type}  \n",
      "2   Premium Type  It is offered in the {Premium Type} category  \n",
      "3   Premium Type        Its premium category is {Premium Type}  \n",
      "4   Premium Type            The premium type is {Premium Type}  \n",
      "\n",
      "Dataset shapes:\n",
      "Level 1: (7, 7)\n",
      "Level 2: (3, 9)\n",
      "Level 3: (21, 8)\n",
      "Level 4: (900, 13)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import libraries and load templates & insurance datasets\n",
    "\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\n",
    "from sentence_transformers import SentenceTransformer, util  # for embedding rows\n",
    "\n",
    "# Load the final templates CSV (generated previously)\n",
    "templates_path = r\"C:\\Users\\lathe\\Desktop\\rag model training\\final_templates.csv\"\n",
    "templates_df = pd.read_csv(templates_path)\n",
    "print(\"Final Templates (first 5 rows):\")\n",
    "print(templates_df.head())\n",
    "\n",
    "# Load insurance data (adjust paths as needed)\n",
    "df_level1 = pd.read_csv(r\"C:\\Users\\lathe\\Desktop\\rag model training\\knowledge_plan_grouping.csv\")\n",
    "df_level2 = pd.read_csv(r\"C:\\Users\\lathe\\Desktop\\rag model training\\knowledge_premium_grouping.csv\")\n",
    "df_level3 = pd.read_csv(r\"C:\\Users\\lathe\\Desktop\\rag model training\\knowlede_plan_disease_combinations.csv\")\n",
    "df_level4 = pd.read_csv(r\"C:\\Users\\lathe\\Desktop\\rag model training\\insurance_plans_by_disease.csv\")  # used for Level 4 and 5\n",
    "\n",
    "print(\"\\nDataset shapes:\")\n",
    "print(\"Level 1:\", df_level1.shape)\n",
    "print(\"Level 2:\", df_level2.shape)\n",
    "print(\"Level 3:\", df_level3.shape)\n",
    "print(\"Level 4:\", df_level4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define target_order, get_all_subsets, join_fragments, and placeholder standardization.\n",
    "\n",
    "# These are our full target definitions (as in our training examples)\n",
    "target_order = {\n",
    "    1: [\"Premium Type\", \"DisCount\", \"Diseases\", \"CoverageLevel\", \"PlanFocus\", \"Advantage\"],\n",
    "    2: [\"Plan Name\", \"Deductible\", \"Co-pay Percentage\", \"Plan Term\", \"Tax Redemption\", \"Plan Count\", \"Monthly Payment\", \"Advantage\"],\n",
    "    3: [\"Monthly Payment\", \"Deductible\", \"Co-pay Percentage\", \"Plan Term\", \"Tax Redemption\", \"Benefits\"],\n",
    "    4: [\"Maximum Coverage\", \"Deductible\", \"Co-pay Percentage\", \"Waiting Period\", \"Claims Settled\", \"Renewability\", \"Hospital Coverage\", \"Benefits\", \"Tax Redemption\"],\n",
    "    5: [\"Calculation\"]\n",
    "}\n",
    "\n",
    "def get_all_subsets(lst):\n",
    "    \"\"\"Return all non-empty subsets of lst.\"\"\"\n",
    "    subsets = []\n",
    "    n = len(lst)\n",
    "    for i in range(1, 2**n):\n",
    "        subset = [lst[j] for j in range(n) if (i >> j) & 1]\n",
    "        subsets.append(subset)\n",
    "    return subsets\n",
    "\n",
    "def join_fragments(fragments):\n",
    "    \"\"\"\n",
    "    Join fragments with commas and \"and\" before the final fragment.\n",
    "    Also, if the first non-intro fragment starts with an unwanted connector (\"and\", \"with\"),\n",
    "    remove it.\n",
    "    \"\"\"\n",
    "    clean = [frag.strip().rstrip(\".,\") for frag in fragments if frag.strip()]\n",
    "    if clean:\n",
    "        for connector, replacement in [(\"and \", \"It \"), (\"with \", \"The \")]:\n",
    "            if clean[0].lower().startswith(connector):\n",
    "                clean[0] = replacement + clean[0][len(connector):].strip()\n",
    "    if not clean:\n",
    "        return \"\"\n",
    "    if len(clean) == 1:\n",
    "        return clean[0]\n",
    "    return \", \".join(clean[:-1]) + \" and \" + clean[-1]\n",
    "\n",
    "def standardize_placeholders(text):\n",
    "    # Replace placeholders with standardized tokens.\n",
    "    replacements = {\n",
    "        \"{Plan Name}\": \"<PLAN_NAME>\",\n",
    "        \"{Premium Type}\": \"<PREMIUM_TYPE>\",\n",
    "        \"{Disease}\": \"<DISEASE>\",\n",
    "        \"{DisCount}\": \"<DISEASE_COUNT>\",\n",
    "        \"{CoverageLevel}\": \"<COVERAGE_LEVEL>\",\n",
    "        \"{PlanFocus}\": \"<PLAN_FOCUS>\",\n",
    "        \"{Advantage}\": \"<ADVANTAGE>\",\n",
    "        \"{Deductible}\": \"<DEDUCTIBLE>\",\n",
    "        \"{Co-pay Percentage}\": \"<COPAY>\",\n",
    "        \"{Plan Term}\": \"<PLAN_TERM>\",\n",
    "        \"{Tax Redemption}\": \"<TAX_REDEMPTION>\",\n",
    "        \"{Plan Count}\": \"<PLAN_COUNT>\",\n",
    "        \"{Monthly Payment}\": \"<MONTHLY_PAYMENT>\",\n",
    "        \"{Benefits}\": \"<BENEFITS>\",\n",
    "        \"{Maximum Coverage}\": \"<MAX_COVERAGE>\",\n",
    "        \"{Waiting Period}\": \"<WAITING_PERIOD>\",\n",
    "        \"{Claims Settled}\": \"<CLAIMS_SETTLED>\",\n",
    "        \"{Renewability}\": \"<RENEWABILITY>\",\n",
    "        \"{Hospital Coverage}\": \"<HOSPITAL_COVERAGE>\",\n",
    "        \"{Calculation}\": \"<CALCULATION>\"\n",
    "    }\n",
    "    for k, v in replacements.items():\n",
    "        text = text.replace(k, v)\n",
    "    return text\n",
    "\n",
    "# Standardize the templates\n",
    "templates_df[\"user_query\"] = templates_df[\"user_query\"].apply(standardize_placeholders)\n",
    "templates_df[\"output_template\"] = templates_df[\"output_template\"].apply(standardize_placeholders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 10500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2626' max='2626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2626/2626 7:32:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.076900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.071500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.070100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.067800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.063200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.059700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.059100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.058200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.057500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.059200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.057300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lathe\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Create Dataset and Fine-Tune BART\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TemplateDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_input_length=128, max_output_length=128):\n",
    "        self.inputs = df[\"user_query\"].tolist()\n",
    "        self.outputs = df[\"output_template\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.inputs[idx]\n",
    "        output_text = self.outputs[idx]\n",
    "        input_enc = self.tokenizer(input_text, truncation=True, padding=\"max_length\",\n",
    "                                    max_length=self.max_input_length, return_tensors=\"pt\")\n",
    "        output_enc = self.tokenizer(output_text, truncation=True, padding=\"max_length\",\n",
    "                                     max_length=self.max_output_length, return_tensors=\"pt\")\n",
    "        return {\n",
    "            \"input_ids\": input_enc[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": input_enc[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": output_enc[\"input_ids\"].squeeze()\n",
    "        }\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "dataset = TemplateDataset(templates_df, tokenizer)\n",
    "print(\"Number of training examples:\", len(dataset))\n",
    "\n",
    "# Fine-tune the model (this example uses a small number of epochs; adjust as needed)\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bart_finetuned\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"no\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./bart_finetuned\")\n",
    "tokenizer.save_pretrained(\"./bart_finetuned\")\n",
    "print(\"Fine-tuning complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Initialize the sentence transformer model for embedding.\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def compute_embeddings(df, fields):\n",
    "    \"\"\"\n",
    "    Given a dataframe and a list of fields (columns),\n",
    "    compute a text representation (concatenation of the fields) and then embed it.\n",
    "    \"\"\"\n",
    "    texts = df[fields].astype(str).apply(lambda row: \" | \".join(row.values), axis=1).tolist()\n",
    "    embeddings = embedder.encode(texts, convert_to_tensor=True)\n",
    "    return embeddings, texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_level(prompt):\n",
    "    prompt_lower = prompt.lower()\n",
    "    if \"amount\" in prompt_lower:\n",
    "        return 5\n",
    "    elif \"disease\" in prompt_lower:\n",
    "        # If both plan and premium are mentioned, assume level 4.\n",
    "        if \"plan\" in prompt_lower and \"premium\" in prompt_lower:\n",
    "            return 4\n",
    "        else:\n",
    "            return 4\n",
    "    elif \"plan\" in prompt_lower and \"premium\" in prompt_lower:\n",
    "        return 3\n",
    "    elif \"premium\" in prompt_lower:\n",
    "        return 2\n",
    "    elif \"plan\" in prompt_lower:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def extract_inputs(prompt):\n",
    "    inputs = {}\n",
    "    plan_match = re.search(r\"Plan(?:\\s*Name)?:\\s*['\\\"]([^'\\\"]+)['\\\"]\", prompt, re.IGNORECASE)\n",
    "    if plan_match:\n",
    "        inputs[\"Plan Name\"] = plan_match.group(1).strip()\n",
    "    premium_match = re.search(r\"Premium(?:\\s*Type)?:\\s*['\\\"]([^'\\\"]+)['\\\"]\", prompt, re.IGNORECASE)\n",
    "    if premium_match:\n",
    "        inputs[\"Premium Type\"] = premium_match.group(1).strip()\n",
    "    disease_match = re.search(r\"Disease(?:\\s*Name)?:\\s*['\\\"]([^'\\\"]+)['\\\"]\", prompt, re.IGNORECASE)\n",
    "    if disease_match:\n",
    "        inputs[\"Disease\"] = disease_match.group(1).strip()\n",
    "    amount_match = re.search(r\"Amount:\\s*([\\d]+)\", prompt, re.IGNORECASE)\n",
    "    if amount_match:\n",
    "        inputs[\"Amount\"] = float(amount_match.group(1))\n",
    "    return inputs\n",
    "\n",
    "def generate_model_response(prompt):\n",
    "    # Use the fine-tuned BART model to generate an output template.\n",
    "    inputs_enc = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "    outputs = model.generate(inputs_enc[\"input_ids\"], attention_mask=inputs_enc[\"attention_mask\"],\n",
    "                             max_length=128, num_beams=5, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def retrieve_best_match(level, inputs, top_k=1):\n",
    "    \"\"\"\n",
    "    Given extracted inputs and the level, select the corresponding dataset and use\n",
    "    cosine similarity over embeddings to find the best matching record.\n",
    "    For simplicity, here we show an example for Level 1; similar logic applies for other levels.\n",
    "    \"\"\"\n",
    "    if level == 1:\n",
    "        df = df_level1.copy()\n",
    "        # Filter based on Plan Name if provided.\n",
    "        if \"Plan Name\" in inputs:\n",
    "            df = df[df[\"Plan Name\"].str.contains(inputs[\"Plan Name\"], case=False, na=False)]\n",
    "        if df.empty:\n",
    "            return None, None\n",
    "        # Compute embeddings for the filtered rows:\n",
    "        embeddings, texts = compute_embeddings(df, df.columns.tolist())\n",
    "        # Create an embedding for the query (e.g., using the input fields)\n",
    "        query_text = \" | \".join([str(inputs[k]) for k in [\"Plan Name\"] if k in inputs])\n",
    "        query_embedding = embedder.encode(query_text, convert_to_tensor=True)\n",
    "        cos_scores = util.cos_sim(query_embedding, embeddings)[0]\n",
    "        top_result_idx = int(torch.argmax(cos_scores))\n",
    "        return df.iloc[top_result_idx].to_dict(), texts[top_result_idx]\n",
    "    # Similarly implement for other levels...\n",
    "    # For brevity, we return the head row for levels 2-4.\n",
    "    elif level in [2,3,4]:\n",
    "        if level == 2:\n",
    "            df = df_level2.copy()\n",
    "        elif level == 3:\n",
    "            df = df_level3.copy()\n",
    "        else:\n",
    "            df = df_level4.copy()\n",
    "        # Simple filtering by matching input fields:\n",
    "        for key, value in inputs.items():\n",
    "            if key in df.columns:\n",
    "                df = df[df[key].str.contains(value, case=False, na=False)]\n",
    "        if df.empty:\n",
    "            return None, None\n",
    "        return df.iloc[0].to_dict(), \"First matched record\"\n",
    "    elif level == 5:\n",
    "        df = df_level4.copy()\n",
    "        for key, value in inputs.items():\n",
    "            if key in df.columns:\n",
    "                df = df[df[key].str.contains(value, case=False, na=False)]\n",
    "        if df.empty:\n",
    "            return None, None\n",
    "        return df.iloc[0].to_dict(), \"First matched record\"\n",
    "    \n",
    "def compute_out_of_pocket(record, amount, premium_type):\n",
    "    premium_type = premium_type.lower()\n",
    "    if \"basic\" in premium_type:\n",
    "        deductible_pct = 5\n",
    "        copay_pct = 20\n",
    "    elif \"lite\" in premium_type:\n",
    "        deductible_pct = 10\n",
    "        copay_pct = 10\n",
    "    elif \"premier\" in premium_type:\n",
    "        deductible_pct = 15\n",
    "        copay_pct = 5\n",
    "    else:\n",
    "        deductible_pct = 5\n",
    "        copay_pct = 20\n",
    "    try:\n",
    "        max_coverage = float(record.get(\"Maximum Coverage\", 0))\n",
    "    except:\n",
    "        max_coverage = 0\n",
    "    if max_coverage > 0 and amount > max_coverage:\n",
    "        return f\"Claim amount {amount} exceeds maximum coverage of {max_coverage}.\"\n",
    "    deductible_value = amount * deductible_pct / 100\n",
    "    updated_amount = amount - deductible_value\n",
    "    copay_value = updated_amount * copay_pct / 100\n",
    "    final_out_of_pocket = deductible_value + copay_value\n",
    "    return final_out_of_pocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Prompt: Plan: 'Individual Health Insurance'\n",
      "Generated Template: the plan has a disease count of <DISEASE_COUNT>\n",
      "\n",
      "Answer: Retrieved data: Plan Name: Individual Health Insurance; Premium Type: Basic, Lite, Premier; DisCount: 34; Diseases: Acute Myocardial Infarction, Alzheimer's Disease, Angina Pectoris, Aorta Surgery, Aortic Dissection, Atrial Flutter, Brain Surgery, Cancer, Cardiomyopathy, Chronic Liver Disease, Chronic Lung Disease, Congestive Heart Failure, Coronary Artery Disease, Endocarditis, Heart Attack, Kidney Failure, Left Ventricular Hypertrophy, Major Organ Transplant, Motor Neuron Disease, Multiple Sclerosis, Myocarditis, Parkinson's Disease, Pericarditis, Permanent Blindness, Permanent Deafness, Permanent Loss of Speech, Poliomyelitis, Primary Pulmonary Arterial Hypertension, Pulmonary Embolism, Sepsis, Severe Coma, Stroke, Ventricular Fibrillation, Ventricular Tachycardia; CoverageLevel: High; PlanFocus: Individual; Advantage: Plan 'Individual Health Insurance' (Individual plan) offers premium options (Basic, Lite, Premier) and covers 34 diseases with High coverage. Key diseases include Acute Myocardial Infarction, Alzheimer's Disease, Angina Pectoris, Aorta Surgery, Aortic Dissection, Atrial Flutter, Brain Surgery, Cancer, Cardiomyopathy, Chronic Liver Disease, Chronic Lung Disease, Congestive Heart Failure, Coronary Artery Disease, Endocarditis, Heart Attack, Kidney Failure, Left Ventricular Hypertrophy, Major Organ Transplant, Motor Neuron Disease, Multiple Sclerosis.\n",
      "\n",
      "User Prompt: Premium: 'Lite'\n",
      "Generated Template: the plan is renewable at <RENEWABILITY> and the plan has a disease count of <DISEASE_COUNT>\n",
      "\n",
      "Answer: Retrieved data: Premium Type: Lite; Plan Name: Accidental Coverage, Children Health Insurance, Covid Coverage, Family Health Insurance, Individual Health Insurance, Parents Health Insurance, Protability Insurance; Deductible: 10%; Co-pay Percentage: 10%; Plan Term: 15 years; Tax Redemption: 10%, 15%, 20%; Plan Count: 7; Monthly Payment: 1988.571428571429; Advantage: Premium 'Lite' is featured in 7 plan(s) and is recognized for being balanced with moderate extra features. It has deductibles of 10%, co-pay percentages of 10%, terms of 15 years and tax redemption of 10%, 15%, 20%. Avg. monthly payment for this premium: 1988.57. Plans offering this premium include: Accidental Coverage, Children Health Insurance, Covid Coverage, Family Health Insurance, Individual Health Insurance, Parents Health Insurance, Protability Insurance.\n",
      "\n",
      "User Prompt: Plan: 'Individual Health Insurance', Premium: 'Basic'\n",
      "Generated Template: the plan has a disease count of <DISEASE_COUNT> and the plan is renewable at <RENEWABILITY>\n",
      "\n",
      "Answer: Retrieved data: Plan Name: Individual Health Insurance; Premium Type: Basic; Monthly Payment: 1800; Deductible: 5%; Co-pay Percentage: 20%; Plan Term: 10 years; Tax Redemption: 10%; Benefits: For Individual Health Insurance (Basic tier), with a representative maximum coverage of Rs.600000, the monthly premium is Rs.1800, the deductible is Rs.60000, and the co-pay is 20%. The plan term is 10 years and tax redemption is 10%.\n",
      "\n",
      "User Prompt: Plan: 'Individual Health Insurance', Premium: 'Basic', Disease: 'Heart Attack'\n",
      "Generated Template: the plan has a disease of <DISEASE_COUNT>\n",
      "\n",
      "Answer: Retrieved data: Plan Name: Individual Health Insurance; Disease: Heart Attack; Premium Type: Basic; Maximum Coverage: 420379; Deductible: 5%; Co-pay Percentage: 20%; Waiting Period: 172; Claims Settled: 90; Renewability: Renewable; Hospital Coverage: 8272; Benefits: Benefit from Rs.420379.0 in disease coverage with Individual Health Insurance Basic, featuring a 5% deductible and 20% co-pay. Coverage starts in 172 days, ensuring the plan is specifically designed for individual coverage.; Tax Redemption: 10%; Unnamed: 12: nan\n",
      "\n",
      "User Prompt: Plan: 'Individual Health Insurance', Premium: 'Basic', Disease: 'Heart Attack', Amount: 300000\n",
      "Generated Template: the plan has a disease count of <DISEASE_COUNT> and the plan is renewable at <RENEWABILITY>\n",
      "\n",
      "Answer: For the plan 'Individual Health Insurance' with premium 'Basic', and disease 'Heart Attack', the calculated out-of-pocket expense is 72000.0.\n"
     ]
    }
   ],
   "source": [
    "def data_retriever_model(user_prompt):\n",
    "    # 1. Determine level and extract inputs.\n",
    "    level = determine_level(user_prompt)\n",
    "    inputs = extract_inputs(user_prompt)\n",
    "    \n",
    "    # 2. Generate an output template using the fine-tuned BART model.\n",
    "    generated_template = generate_model_response(user_prompt)\n",
    "    \n",
    "    # 3. Retrieve the best matching record using our embedding/retrieval method.\n",
    "    record, record_text = retrieve_best_match(level, inputs)\n",
    "    if record is None:\n",
    "        return \"No matching record found.\"\n",
    "    \n",
    "    # 4. For Level 5, if amount is provided, compute the out-of-pocket expense.\n",
    "    if level == 5:\n",
    "        if \"Amount\" in inputs:\n",
    "            result = compute_out_of_pocket(record, inputs[\"Amount\"], inputs.get(\"Premium Type\", \"basic\"))\n",
    "            answer = (f\"For the plan '{record.get('Plan Name', 'Unknown')}' with premium '{record.get('Premium Type', 'Unknown')}', \"\n",
    "                      f\"and disease '{record.get('Disease', 'Unknown')}', the calculated out-of-pocket expense is {result}.\")\n",
    "        else:\n",
    "            try:\n",
    "                default_amount = float(record.get(\"Maximum Coverage\", 0))\n",
    "            except:\n",
    "                default_amount = 0\n",
    "            result = compute_out_of_pocket(record, default_amount, inputs.get(\"Premium Type\", \"basic\"))\n",
    "            answer = (f\"For the plan '{record.get('Plan Name', 'Unknown')}' with premium '{record.get('Premium Type', 'Unknown')}', \"\n",
    "                      f\"and disease '{record.get('Disease', 'Unknown')}', assuming maximum coverage as the claim amount, \"\n",
    "                      f\"the calculated out-of-pocket expense is {result}.\")\n",
    "    else:\n",
    "        # For levels 1-4, simply format the retrieved record.\n",
    "        answer = \"Retrieved data: \" + \"; \".join([f\"{k}: {v}\" for k, v in record.items()])\n",
    "    \n",
    "    final_response = f\"Generated Template: {generated_template}\\n\\nAnswer: {answer}\"\n",
    "    return final_response\n",
    "\n",
    "# Test the full pipeline with example prompts:\n",
    "test_prompts = [\n",
    "    \"Plan: 'Individual Health Insurance'\",\n",
    "    \"Premium: 'Lite'\",\n",
    "    \"Plan: 'Individual Health Insurance', Premium: 'Basic'\",\n",
    "    \"Plan: 'Individual Health Insurance', Premium: 'Basic', Disease: 'Heart Attack'\",\n",
    "    \"Plan: 'Individual Health Insurance', Premium: 'Basic', Disease: 'Heart Attack', Amount: 300000\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(\"\\nUser Prompt:\", prompt)\n",
    "    print(data_retriever_model(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
